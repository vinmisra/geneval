{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustration of how to perform automated evaluation of finetune experiments. Recommended!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "import sdtools.sdexp as sdexp\n",
    "import sdtools.cfg as cfg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the evaluation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = cfg.data_dir\n",
    "N_SAMPLES_EVAL = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "lst_img = pickle.load(open(cfg.path_labeled_img, 'rb'))\n",
    "lst_instance_labels, lst_prompt_labels = pickle.load(open(cfg.path_labeled_labels, 'rb'))\n",
    "clf_quality = sdexp.CLFQuality(lst_img=lst_img, lst_instance_labels=lst_instance_labels, lst_prompt_labels=lst_prompt_labels, path_cache=cfg.path_clf_quality, force_retrain=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example experiment comparing the performance of multiple training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "spec_base = {\n",
    "    \"exp\":None,\n",
    "    \"entities\":[\n",
    "        {\n",
    "            \"finetune_path\":None,\n",
    "            \"class_prompt\":\"a cell phone photo of a kid\",\n",
    "            \"finetune_prompt\":\"a cell phone photo of alskj kid\",\n",
    "            \"n_class_img\":200\n",
    "        }\n",
    "    ],\n",
    "    \"lr\":1e-6,\n",
    "    \"n_iters\":[1500,2800,3500],\n",
    "    \"dir_model\":None,\n",
    "    \"dir_parent_classimg\":os.path.join(ROOT_DIR,\"class_sets\"),\n",
    "    \"test_prompts\":\n",
    "        [\n",
    "            \"alskj kid sits in a cornfield, smiling. Watercolor.\"\n",
    "        ]\n",
    "}\n",
    "lst_spec = []\n",
    "for exp,path in [\n",
    "    (\"A2\",\"finetune_sets/entityboy_small\"),\n",
    "    (\"A3\",\"finetune_sets/entityboy_large\"),\n",
    "    (\"A4\",\"finetune_sets/entityboy_ablationA\"),\n",
    "    (\"A5\",\"finetune_sets/entityboy_ablationB\"),\n",
    "    (\"A6\",\"finetune_sets/entityboy_ablationC\"),\n",
    "]:\n",
    "    spec = copy.deepcopy(spec_base)\n",
    "    spec['exp'] = exp\n",
    "    spec['dir_model']=os.path.join(ROOT_DIR,f\"modelexp/{exp}\")\n",
    "    spec['entities'][0]['finetune_path'] = os.path.join(ROOT_DIR,path)\n",
    "    lst_spec.append(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for spec in lst_spec:\n",
    "    results[exp] = {}\n",
    "    for iters in spec['n_iters']:\n",
    "        lst_test_img = sdexp.sample_exp(spec, iters=iters, n_samples=N_SAMPLES_EVAL)\n",
    "        score_instance, score_prompt = clf_quality.predict_proba(lst_test_img)\n",
    "        print(\n",
    "            spec['exp'], \n",
    "            '%.2f'%(np.mean(score_instance[:,clf_quality.clf_instance.classes_.tolist().index(1)])), \n",
    "            '%.2f'%(np.mean(score_prompt[:,clf_quality.clf_prompt.classes_.tolist().index(1)]))\n",
    "        )\n",
    "        results[iters] = {\n",
    "            'instance':score_instance,\n",
    "            'prompt':score_prompt\n",
    "        }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#Flatten results dictionary and put it into a dataframe\n",
    "df_results = pd.DataFrame.from_dict({\n",
    "    (i,j): results[i][j]\n",
    "    for i in results.keys()\n",
    "    for j in results[i].keys()\n",
    "}, orient='index')\n",
    "df_results['combined'] = df_results['instance']*df_results['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
